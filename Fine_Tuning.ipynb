{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-04T05:19:30.144230Z",
     "iopub.status.busy": "2023-05-04T05:19:30.143657Z",
     "iopub.status.idle": "2023-05-04T05:19:30.163630Z",
     "shell.execute_reply": "2023-05-04T05:19:30.162334Z",
     "shell.execute_reply.started": "2023-05-04T05:19:30.144197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-data/new_dataset/Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:19:30.166717Z",
     "iopub.status.busy": "2023-05-04T05:19:30.166359Z",
     "iopub.status.idle": "2023-05-04T05:19:41.350073Z",
     "shell.execute_reply": "2023-05-04T05:19:41.348824Z",
     "shell.execute_reply.started": "2023-05-04T05:19:30.166686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting language_tool_python\n",
      "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from language_tool_python) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from language_tool_python) (4.64.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->language_tool_python) (2.1.1)\n",
      "Installing collected packages: language_tool_python\n",
      "Successfully installed language_tool_python-2.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install language_tool_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-04T05:19:41.352447Z",
     "iopub.status.busy": "2023-05-04T05:19:41.352083Z",
     "iopub.status.idle": "2023-05-04T05:20:05.451856Z",
     "shell.execute_reply": "2023-05-04T05:20:05.450728Z",
     "shell.execute_reply.started": "2023-05-04T05:19:41.352406Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import language_tool_python\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data Into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.455413Z",
     "iopub.status.busy": "2023-05-04T05:20:05.454596Z",
     "iopub.status.idle": "2023-05-04T05:20:05.677234Z",
     "shell.execute_reply": "2023-05-04T05:20:05.676321Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.455371Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/nlp-data/new_dataset/Dataset.csv\")\n",
    "df.rename(columns = {\"0\":\"transcript\",\"1\":\"summary\"},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.679137Z",
     "iopub.status.busy": "2023-05-04T05:20:05.678767Z",
     "iopub.status.idle": "2023-05-04T05:20:05.694398Z",
     "shell.execute_reply": "2023-05-04T05:20:05.693406Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.679090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My name is Eric, diligent from shifts in Moria...</td>\n",
       "      <td>Eric, a recent graduate from Stanford Univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you very much.I hope you understand me.I...</td>\n",
       "      <td>This text discusses the difficult task of link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon everyone.My name is Yoshimi Cla...</td>\n",
       "      <td>Yoshimi Clara, the Secretary General of Jay MC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK, so this is a tutorial tutorial on the new ...</td>\n",
       "      <td>This tutorial is about Velebit 5.0, an open so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everybody, so my name is Vicki and.For the nex...</td>\n",
       "      <td>This work looks at the issue of duplicate inst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  My name is Eric, diligent from shifts in Moria...   \n",
       "1  Thank you very much.I hope you understand me.I...   \n",
       "2  Good afternoon everyone.My name is Yoshimi Cla...   \n",
       "3  OK, so this is a tutorial tutorial on the new ...   \n",
       "4  Everybody, so my name is Vicki and.For the nex...   \n",
       "\n",
       "                                             summary  \n",
       "0   Eric, a recent graduate from Stanford Univers...  \n",
       "1  This text discusses the difficult task of link...  \n",
       "2  Yoshimi Clara, the Secretary General of Jay MC...  \n",
       "3  This tutorial is about Velebit 5.0, an open so...  \n",
       "4  This work looks at the issue of duplicate inst...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into Train, Test , Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.696454Z",
     "iopub.status.busy": "2023-05-04T05:20:05.695677Z",
     "iopub.status.idle": "2023-05-04T05:20:05.704868Z",
     "shell.execute_reply": "2023-05-04T05:20:05.703865Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.696419Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df,test_df = train_test_split(df,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.707115Z",
     "iopub.status.busy": "2023-05-04T05:20:05.706370Z",
     "iopub.status.idle": "2023-05-04T05:20:05.714062Z",
     "shell.execute_reply": "2023-05-04T05:20:05.713117Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.707079Z"
    }
   },
   "outputs": [],
   "source": [
    "train,val = train_test_split(train_df,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converted the Pandas Dataframe into Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.716684Z",
     "iopub.status.busy": "2023-05-04T05:20:05.715958Z",
     "iopub.status.idle": "2023-05-04T05:20:05.729055Z",
     "shell.execute_reply": "2023-05-04T05:20:05.727971Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.716649Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train.to_dict('records')\n",
    "valid_data = val.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.731323Z",
     "iopub.status.busy": "2023-05-04T05:20:05.730539Z",
     "iopub.status.idle": "2023-05-04T05:20:05.744294Z",
     "shell.execute_reply": "2023-05-04T05:20:05.743341Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.731283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276, 319)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:05.750537Z",
     "iopub.status.busy": "2023-05-04T05:20:05.749595Z",
     "iopub.status.idle": "2023-05-04T05:20:30.878885Z",
     "shell.execute_reply": "2023-05-04T05:20:30.877996Z",
     "shell.execute_reply.started": "2023-05-04T05:20:05.750507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43181a96b3af4d29b9174e549b2442a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80807e135ffc4fa0a5fa39b20f3c2085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f0205040234406aa6bf05a010ba09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f7531f5e1f43c3acba06f2f32241a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To convert Train & Validation Dataset into Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.880825Z",
     "iopub.status.busy": "2023-05-04T05:20:30.880100Z",
     "iopub.status.idle": "2023-05-04T05:20:30.887408Z",
     "shell.execute_reply": "2023-05-04T05:20:30.886405Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.880790Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        input_text = item['transcript']\n",
    "        target_text = item['summary']\n",
    "        return {'transcript': input_text, 'summary': target_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Convert the Tokenized Data into Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.889596Z",
     "iopub.status.busy": "2023-05-04T05:20:30.888681Z",
     "iopub.status.idle": "2023-05-04T05:20:30.902464Z",
     "shell.execute_reply": "2023-05-04T05:20:30.901636Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.889556Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset1(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        input_id = item['input_ids']\n",
    "        input_mask = item['attention_mask']\n",
    "        target_id = item['target_ids']\n",
    "        return {'input_ids': input_id, 'attention_mask': input_mask , 'labels': target_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Tokenize the Train & Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.904879Z",
     "iopub.status.busy": "2023-05-04T05:20:30.903876Z",
     "iopub.status.idle": "2023-05-04T05:20:30.911929Z",
     "shell.execute_reply": "2023-05-04T05:20:30.911045Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.904844Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(data):\n",
    "    input_text = data['transcript']\n",
    "    target_text = data['summary']\n",
    "    # Tokenize the input and target text\n",
    "    input_tokens = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    target_tokens = tokenizer.encode_plus(\n",
    "        target_text,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': input_tokens['input_ids'].squeeze(),\n",
    "        'attention_mask': input_tokens['attention_mask'].squeeze(),\n",
    "        'target_ids': target_tokens['input_ids'].squeeze(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammaticality Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.913788Z",
     "iopub.status.busy": "2023-05-04T05:20:30.913168Z",
     "iopub.status.idle": "2023-05-04T05:20:30.922298Z",
     "shell.execute_reply": "2023-05-04T05:20:30.921363Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.913561Z"
    }
   },
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "def grammaticality_loss_function(output_logits):\n",
    "    output_sentences = tokenizer.batch_decode(torch.argmax(output_logits, dim=-1), skip_special_tokens=True)\n",
    "    loss = 0.0\n",
    "    cnt = 0\n",
    "    for output in output_sentences:\n",
    "        matches = tool.check(output)\n",
    "        num_errors = len(matches)\n",
    "        cnt += len(output.split())\n",
    "        loss += num_errors\n",
    "    loss /= cnt    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Trainer which includes compute loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.924056Z",
     "iopub.status.busy": "2023-05-04T05:20:30.923581Z",
     "iopub.status.idle": "2023-05-04T05:20:30.933230Z",
     "shell.execute_reply": "2023-05-04T05:20:30.932348Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.924020Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.args.train_batch_size, \n",
    "            collate_fn=self.data_collator, \n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def get_eval_dataloader(self,eval_dataset):\n",
    "        return DataLoader(\n",
    "            self.eval_dataset, \n",
    "            batch_size=self.args.eval_batch_size, \n",
    "            collate_fn=self.data_collator\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs['labels']\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=inputs['labels'])\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # compute custom loss\n",
    "        grammaticality_loss = grammaticality_loss_function(logits.view(-1, self.model.config.vocab_size))\n",
    "        \n",
    "        # compute cross entropy loss\n",
    "        ce_loss_fct = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "        ce_loss = ce_loss_fct(logits.view(-1, model.module.config.vocab_size), labels.view(-1))\n",
    "        \n",
    "        # combine losses\n",
    "        total_loss = grammaticality_loss*0.1 + ce_loss\n",
    "        \n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the Train Dataset into Pytorch Dataset and then Tokenizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:30.935232Z",
     "iopub.status.busy": "2023-05-04T05:20:30.934908Z",
     "iopub.status.idle": "2023-05-04T05:20:37.744399Z",
     "shell.execute_reply": "2023-05-04T05:20:37.743193Z",
     "shell.execute_reply.started": "2023-05-04T05:20:30.935202Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/1794968117.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dict_list = [{'input_ids': torch.tensor(example['input_ids']),\n",
      "/tmp/ipykernel_32/1794968117.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask': torch.tensor(example['attention_mask']),\n",
      "/tmp/ipykernel_32/1794968117.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'target_ids': torch.tensor(example['target_ids'])} for example in train_dict_list]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "train_dataset = CustomDataset(train_data)\n",
    "train_dict_list = list(train_dataset)\n",
    "train_dict_list = [preprocess_function(example) for example in train_dict_list]\n",
    "train_dict_list = [{'input_ids': torch.tensor(example['input_ids']),\n",
    "                    'attention_mask': torch.tensor(example['attention_mask']),\n",
    "                    'target_ids': torch.tensor(example['target_ids'])} for example in train_dict_list]\n",
    "train_dataset = CustomDataset1(train_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the Validation Dataset into Pytorch Dataset and then Tokenizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:37.746890Z",
     "iopub.status.busy": "2023-05-04T05:20:37.745960Z",
     "iopub.status.idle": "2023-05-04T05:20:39.583848Z",
     "shell.execute_reply": "2023-05-04T05:20:39.582828Z",
     "shell.execute_reply.started": "2023-05-04T05:20:37.746852Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/1384287669.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_dict_list = [{'input_ids': torch.tensor(example['input_ids']),\n",
      "/tmp/ipykernel_32/1384287669.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask': torch.tensor(example['attention_mask']),\n",
      "/tmp/ipykernel_32/1384287669.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'target_ids': torch.tensor(example['target_ids'])} for example in valid_dict_list]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "valid_dataset = CustomDataset(valid_data)\n",
    "valid_dict_list = list(valid_dataset)\n",
    "valid_dict_list = [preprocess_function(example) for example in valid_dict_list]\n",
    "valid_dict_list = [{'input_ids': torch.tensor(example['input_ids']),\n",
    "                    'attention_mask': torch.tensor(example['attention_mask']),\n",
    "                    'target_ids': torch.tensor(example['target_ids'])} for example in valid_dict_list]\n",
    "valid_dataset = CustomDataset1(valid_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:39.586175Z",
     "iopub.status.busy": "2023-05-04T05:20:39.585493Z",
     "iopub.status.idle": "2023-05-04T05:20:39.602828Z",
     "shell.execute_reply": "2023-05-04T05:20:39.599423Z",
     "shell.execute_reply.started": "2023-05-04T05:20:39.586138Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='model_save',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type='linear', \n",
    "    warmup_steps=0,\n",
    "    dataloader_num_workers=4,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:39.607508Z",
     "iopub.status.busy": "2023-05-04T05:20:39.606919Z",
     "iopub.status.idle": "2023-05-04T05:20:39.612922Z",
     "shell.execute_reply": "2023-05-04T05:20:39.611395Z",
     "shell.execute_reply.started": "2023-05-04T05:20:39.607467Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:39.616972Z",
     "iopub.status.busy": "2023-05-04T05:20:39.615581Z",
     "iopub.status.idle": "2023-05-04T05:20:39.907503Z",
     "shell.execute_reply": "2023-05-04T05:20:39.906569Z",
     "shell.execute_reply.started": "2023-05-04T05:20:39.616900Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset = valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:39.909240Z",
     "iopub.status.busy": "2023-05-04T05:20:39.908898Z",
     "iopub.status.idle": "2023-05-04T05:20:39.925344Z",
     "shell.execute_reply": "2023-05-04T05:20:39.924447Z",
     "shell.execute_reply.started": "2023-05-04T05:20:39.909209Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "trainer.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:20:39.927318Z",
     "iopub.status.busy": "2023-05-04T05:20:39.926993Z",
     "iopub.status.idle": "2023-05-04T05:36:20.147588Z",
     "shell.execute_reply": "2023-05-04T05:36:20.146372Z",
     "shell.execute_reply.started": "2023-05-04T05:20:39.927287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230504_052054-z617cj7k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/top_g/huggingface/runs/z617cj7k' target=\"_blank\">carbonite-astromech-49</a></strong> to <a href='https://wandb.ai/top_g/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/top_g/huggingface' target=\"_blank\">https://wandb.ai/top_g/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/top_g/huggingface/runs/z617cj7k' target=\"_blank\">https://wandb.ai/top_g/huggingface/runs/z617cj7k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [477/477 14:44, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.398300</td>\n",
       "      <td>2.075030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.052400</td>\n",
       "      <td>2.043393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.949100</td>\n",
       "      <td>2.035646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=477, training_loss=2.1334996253439464, metrics={'train_runtime': 940.1929, 'train_samples_per_second': 4.072, 'train_steps_per_second': 0.507, 'total_flos': 2323783310376960.0, 'train_loss': 2.1334996253439464, 'epoch': 2.99})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the best Model depending on Evaluation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:36:20.150700Z",
     "iopub.status.busy": "2023-05-04T05:36:20.148922Z",
     "iopub.status.idle": "2023-05-04T05:36:23.763559Z",
     "shell.execute_reply": "2023-05-04T05:36:23.759576Z",
     "shell.execute_reply.started": "2023-05-04T05:36:20.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:36:23.765378Z",
     "iopub.status.busy": "2023-05-04T05:36:23.765015Z",
     "iopub.status.idle": "2023-05-04T05:36:27.482221Z",
     "shell.execute_reply": "2023-05-04T05:36:27.481094Z",
     "shell.execute_reply.started": "2023-05-04T05:36:23.765341Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "trained_tokenizer = T5Tokenizer.from_pretrained('./model_save')\n",
    "\n",
    "# load the model\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained('./model_save', \n",
    "                                                  state_dict=torch.load('./model_save/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:36:27.484008Z",
     "iopub.status.busy": "2023-05-04T05:36:27.483480Z",
     "iopub.status.idle": "2023-05-04T05:36:27.725520Z",
     "shell.execute_reply": "2023-05-04T05:36:27.724549Z",
     "shell.execute_reply.started": "2023-05-04T05:36:27.483973Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model = trained_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function To Generate Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:36:27.733354Z",
     "iopub.status.busy": "2023-05-04T05:36:27.730871Z",
     "iopub.status.idle": "2023-05-04T05:36:28.364414Z",
     "shell.execute_reply": "2023-05-04T05:36:28.363311Z",
     "shell.execute_reply.started": "2023-05-04T05:36:27.733313Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_summary(model,tokenizer,input_text):\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    summary_ids = model.generate(input_ids, num_beams=4, max_length=128, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Summaries for Test Data using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:36:28.366221Z",
     "iopub.status.busy": "2023-05-04T05:36:28.365623Z",
     "iopub.status.idle": "2023-05-04T05:52:04.443469Z",
     "shell.execute_reply": "2023-05-04T05:52:04.442549Z",
     "shell.execute_reply.started": "2023-05-04T05:36:28.366162Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [15:34<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the model's summaries for the test data\n",
    "reference_summaries = []\n",
    "generated_summaries = []\n",
    "for i in tqdm(range(test_df.shape[0])):\n",
    "    generated_summary = generate_summary(trained_model, trained_tokenizer,test_df.iloc[i][\"transcript\"])\n",
    "    generated_summaries.append(generated_summary)\n",
    "    reference_summaries.append(test_df.iloc[i][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:32:25.139830Z",
     "iopub.status.busy": "2023-05-04T06:32:25.139389Z",
     "iopub.status.idle": "2023-05-04T06:32:25.150130Z",
     "shell.execute_reply": "2023-05-04T06:32:25.148947Z",
     "shell.execute_reply.started": "2023-05-04T06:32:25.139790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker is not a fan of summer and prefers autumn. They were excited to see people doing autumn art work on Instagram and their art usually has earth tones. They were looking for a sword image to get an idea of what a handle would look like and then copy and paste it. They also mentioned how they had accidentally locked their keyboard by holding down shift too long and had to figure out how to fix it.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_summaries[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:52:04.450482Z",
     "iopub.status.busy": "2023-05-04T05:52:04.449882Z",
     "iopub.status.idle": "2023-05-04T05:52:04.458996Z",
     "shell.execute_reply": "2023-05-04T05:52:04.457204Z",
     "shell.execute_reply.started": "2023-05-04T05:52:04.450445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This text is about a person who is not a big fan of summer and is excited to start doing fall art work this year. They are looking up images of a sword with a handguard and are trying to get an idea of what a handle would look like. They also mention that they accidentally locked their keyboard by holding down shift for 8 or 10 seconds and it took them so long to figure out how to fix it.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T06:32:38.669279Z",
     "iopub.status.busy": "2023-05-04T06:32:38.668568Z",
     "iopub.status.idle": "2023-05-04T06:32:38.679486Z",
     "shell.execute_reply": "2023-05-04T06:32:38.678382Z",
     "shell.execute_reply.started": "2023-05-04T06:32:38.669241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This text is about creating a pet character in Illustrator. The author wants to use the Unite tool to create a simple shape, delete the pieces they don't need, and use a clipping mask to put the shape inside the body. Then they will create legs using a rectangle and the Mirror Me tool. Finally, they will draw an ellipse and use the pen tool to create a droplet.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:58:12.661426Z",
     "iopub.status.busy": "2023-05-04T05:58:12.660886Z",
     "iopub.status.idle": "2023-05-04T05:58:12.675210Z",
     "shell.execute_reply": "2023-05-04T05:58:12.674331Z",
     "shell.execute_reply.started": "2023-05-04T05:58:12.661391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This text is about creating shapes for a project. The author is using the Unite tool to cut out half of the circle and create the legs for the pet and fire drops. They are using the mirror me tool to create the legs and fire drops. They are also using the Unite tool to delete the pieces they don't need.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:52:04.498277Z",
     "iopub.status.busy": "2023-05-04T05:52:04.497903Z",
     "iopub.status.idle": "2023-05-04T05:52:15.057694Z",
     "shell.execute_reply": "2023-05-04T05:52:15.056431Z",
     "shell.execute_reply.started": "2023-05-04T05:52:04.498242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Rouge Score for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:52:15.066301Z",
     "iopub.status.busy": "2023-05-04T05:52:15.063339Z",
     "iopub.status.idle": "2023-05-04T05:52:17.415926Z",
     "shell.execute_reply": "2023-05-04T05:52:17.414258Z",
     "shell.execute_reply.started": "2023-05-04T05:52:15.066253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.3505143293478747, 'p': 0.4519901850493025, 'f': 0.3885615926694993}, 'rouge-2': {'r': 0.13400064123920188, 'p': 0.1783929203554601, 'f': 0.15038960843226018}, 'rouge-l': {'r': 0.3232046444216759, 'p': 0.41772087908719113, 'f': 0.3586954440681843}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(generated_summaries, reference_summaries, avg=True)\n",
    "\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
